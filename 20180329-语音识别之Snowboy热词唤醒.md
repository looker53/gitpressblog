---
layout: post
title: 语音识别之Snowboy热词唤醒
date: 2018-03-29 19:56:03
category: program
keywords:
- 语音识别
- snowboy
tags: 语音识别
---

语音识别在现实中有非常广泛的应用，比如手机中的语音助手，智能音响和电视盒子的语音控制，更有像科大讯飞这样完全靠语音识别发展成巨头的公司。语音识别一般包含三个阶段：热词唤醒阶段，语音录入和识别阶段和逻辑控制阶段。
<!--more-->
热词唤醒阶段就是唤醒设备，让设备倾听你接下来的话。通常设备是时时刻刻都在收录周围的声音的，但是此时它不会对这些声音有任何反映，当通过像「Hi,Siri」这样的唤醒词被唤醒以后，设备就开始处理接下来的声音了。热词唤醒是语音识别的开端。

[Snowboy](https://snowboy.kitt.ai) 是比较流行的热词唤醒框架，目前已经被百度收购。Snowboy 对中文支持友好，相对 [Pocketsphinx](https://cmusphinx.github.io/) 配置使用较为简单，推荐使用。

## 安装

Snowboy 安装主要需要录音方面的依赖。

```bash
sudo apt-get install python-pyaudio python3-pyaudio sox
```

python 依赖：

```bash
pip install pyaudio
```

如果使用的是树莓派，你还需要在 ~/.asoundrc 更改声卡设置：

```bash
pcm.!default {
  type asym
   playback.pcm {
     type plug
     slave.pcm "hw:0,0"
   }
   capture.pcm {
     type plug
     slave.pcm "hw:1,0"
   }
}

```

## 快速开始

GitHub 上有比较详细的 [Demo](https://github.com/Kitt-AI/snowboy/tree/master/examples)，强烈建议先看看。先创建一个 HotwordDetect 类，这个类包含唤醒模型，声音增益，灵敏度等参数。然后初始化 Detector 对象，Snowboy 的 Detector 类存在下载下来的源码里。训练模型可以是单个，也可以是列表形式。

```python
from .. import snowboydetect

class HotwordDetect(object):
    def __init__(self, decoder_model,
                 resource,
                 sensitivity=0.38,
                 audio_gain=1):
        """init"""
        self.detector = snowboydetect.SnowboyDetect(
            resource_filename=resource.encode(),
            model_str=decoder_model.encode())
        self.detector.SetAudioGain(audio_gain)
```

初始化以后可以创建启动方法，启动方法一般会指定一个唤醒回调函数，也就是 「Hi,Siri」之后可能出现的「叮」声；还可以指定录音回调函数，也就是设备唤醒以后你需要用这些声音去干什么：

```python
class HotwordDetect(object):
    ...
    def listen(self, detected_callback,
              interrupt_check=lambda: False,
              audio_recorder_callback):
        """begin to listen"""
        ...
        state = "PASSIVE"
        while True:
            status = self.detector.RunDetection(data)
            ...
            if state == "PASSIVE":
                tetected_callback()
                state = "ACTIVE"
                continue
            elif state == "ACTIVE":
                audio_recorder_callback()
                state = "ACTIVE"
                continue
```

这里的逻辑可以自己去定义，主要是在两个状态间切换，当设备接收到唤醒词以后，status 会指出被识别到的唤醒词的序号，比如你定义了 「Siri」和 「Xiaowei」两个唤醒词，status 为 1 就表示 Siri 被唤醒，status 为 2 就表示 Xiaowei 被唤醒。然后将状态改成激活状态，这个时候执行 audio_recorder_callback 方法，执行完后将状态切换回唤醒状态。

## 在线语音识别

当设备被唤醒以后，你可以拿到录音数据去做任何想做的事情，包括调取百度等语音识别接口。这些逻辑都包含在 audio_recorder_callback 回调方法中。需要注意的是 Snowboy 目前只支持 16000 的录音采样率，其他采样率的录音数据都不能使用，你可以通过两种办法来解决：

- 使用支持 16000 采样率的声卡
- 进行录音数据的采样率转换

目前比较大的两家声卡芯片公司 [C-Media](https://www.cmedia.com.tw/products/USB20_FULL_SPEED) 和 RealTek 一般产品都是 48k 以上的，支持 16k 的芯片一般比较贵，可能到 60 元左右。「绿联」有两款产品可以支持，购买时请查看产品参数，对照芯片公司的产品型号是否支持 16k 采样。

## 声音模型的训练

官方提供两种模式进行个性化声音模型创建：

- [website](https://snowboy.kitt.ai/dashboard)。只要你有 GitHub，Google 和 Facebook 帐号中的一种，登录就可以录音完成训练。
- [train-api](http://docs.kitt.ai/snowboy/#api-v1-train)。根据文档传指定的参数就可以完成训练，api 返回给你升学模型的数据。

这两种方式获得的都是私人的声音模型，获取的是 `.pmdl`的文件形式。一般化的 universal 模型不提供，需要联系官方商业合作。获取到的模型，越多人测试准确率越高，为了提高准确率，你可以邀请更多人来测试你的模型。还有麦克风的种类也会影响准确度，在什么设备上使用就在那个设备上训练模型能提高准确率。语音识别是一个比较精尖的技术，需要注意很多问题，正如 ChenGuo 说的：

> Speech Recognition is not that easy.

